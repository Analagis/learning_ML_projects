**For which of the models already studied is the curse of dimensionality relevant and explain why.**

Модели, подверженные значительному влиянию проклятия размерности алгоритмы, основанные на расстояниях, в частности, k-NN и k-means. Это связано с тем, что в пространствах высокой размерности данные становятся очень разреженными, что затрудняет поиск близких точек.

**What is the difference between PCA and SVD?**

`PCA - это метод снижения размерности, а SVD - метод матричного разложения. PCA может быть реализован на основе SVD, если данные центрированы (среднее значение каждого признака равно нулю).`

**What is the difference between NMF and SVD?**

`NMF разлагает матрицу на неотрицательные компоненты, что делает их более интерпретируемыми, но является приближенным методом. SVD — это точное разложение, но его компоненты могут быть знакопеременными и сложнее для интерпретации. NMF требует, чтобы исходная матрица содержала только неотрицательные значения `

**Describe the structure of the Locally Linear Embedding (LLE) dimension reduction algorithm.**

`LLE — это нелинейный метод снижения размерности. LLE сохраняет локальные свойства данных, представляя каждую точку как линейную комбинацию её ближайших соседей.`

Этапы:
* Выбор k ближайших соседей
* Восстановление весов, минимизирующих ошибку реконструкции текущей точки из соседних
* Поиск низкоразмерного представления данных, которое наилучшим образом сохраняет вычисленные веса